<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Spark on Apache Polaris</title><link>https://polaris.apache.org/tags/spark/</link><description>Recent content in Spark on Apache Polaris</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>&lt;a href="https://www.apache.org/">Copyright Â© 2026 The Apache Software Foundation&lt;/a>.&lt;br>Licensed under the &lt;a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License, Version 2.0&lt;/a>.</copyright><atom:link href="https://polaris.apache.org/tags/spark/index.xml" rel="self" type="application/rss+xml"/><item><title>Getting Started with Apache Polaris and Apache Spark</title><link>https://polaris.apache.org/guides/spark/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://polaris.apache.org/guides/spark/</guid><description>This getting started guide provides a docker-compose file to set up Apache Spark with Apache Polaris. Apache Polaris is configured as an Iceberg REST Catalog in Spark. A Jupyter notebook is used to run PySpark.
Build the Polaris imageðŸ”— If a Polaris image is not already present locally, build one with the following command:
./gradlew \ :polaris-server:assemble \ :polaris-server:quarkusAppPartsBuild --rerun \ -Dquarkus.container-image.build=true Run the docker-compose fileðŸ”— To start the docker-compose file with the necessary dependencies, run these commands from the repo&amp;rsquo;s root directory:</description></item></channel></rss>